{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4459, 4730)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "test_ID = test['ID']\n",
    "y_train = train['target']\n",
    "y_train = np.log1p(y_train)\n",
    "train.drop(\"ID\", axis = 1, inplace = True)\n",
    "train.drop(\"target\", axis = 1, inplace = True)\n",
    "test.drop(\"ID\", axis = 1, inplace = True)\n",
    "cols_with_onlyone_val = train.columns[train.nunique() == 1]\n",
    "train.drop(cols_with_onlyone_val.values, axis=1, inplace=True)\n",
    "test.drop(cols_with_onlyone_val.values, axis=1, inplace=True)\n",
    "NUM_OF_DECIMALS = 32\n",
    "train = train.round(NUM_OF_DECIMALS)\n",
    "test = test.round(NUM_OF_DECIMALS)\n",
    "colsToRemove = []\n",
    "columns = train.columns\n",
    "for i in range(len(columns)-1):\n",
    "    v = train[columns[i]].values\n",
    "    dupCols = []\n",
    "    for j in range(i + 1,len(columns)):\n",
    "        if np.array_equal(v, train[columns[j]].values):\n",
    "            colsToRemove.append(columns[j])\n",
    "train.drop(colsToRemove, axis=1, inplace=True) \n",
    "test.drop(colsToRemove, axis=1, inplace=True) \n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5221083152149821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4459, 1000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "random_seed = 1234\n",
    "NUM_OF_FEATURES = 1000\n",
    "def rmsle(y, pred):\n",
    "    return np.sqrt(np.mean(np.power(y - pred, 2)))\n",
    "\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(\n",
    "    train, y_train.values, test_size=0.20, random_state=random_seed)\n",
    "model = ensemble.RandomForestRegressor(n_jobs=-1, random_state=7)\n",
    "model.fit(x1, y1)\n",
    "print(rmsle(y2, model.predict(x2)))\n",
    "\n",
    "col = pd.DataFrame({'importance': model.feature_importances_, 'feature': train.columns}).sort_values(\n",
    "    by=['importance'], ascending=[False])[:NUM_OF_FEATURES]['feature'].values\n",
    "train = train[col]\n",
    "test = test[col]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "THRESHOLD_P_VALUE = 0.01 #need tuned\n",
    "THRESHOLD_STATISTIC = 0.3 #need tuned\n",
    "diff_cols = []\n",
    "for col in train.columns:\n",
    "    statistic, pvalue = ks_2samp(train[col].values, test[col].values)\n",
    "    if pvalue <= THRESHOLD_P_VALUE and np.abs(statistic) > THRESHOLD_STATISTIC:\n",
    "        diff_cols.append(col)\n",
    "for col in diff_cols:\n",
    "    if col in train.columns:\n",
    "        train.drop(col, axis=1, inplace=True)\n",
    "        test.drop(col, axis=1, inplace=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 1111)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import random_projection\n",
    "ntrain = len(train)\n",
    "ntest = len(test)\n",
    "tmp = pd.concat([train,test])#RandomProjection\n",
    "weight = ((train != 0).sum()/len(train)).values\n",
    "tmp_train = train[train!=0]\n",
    "tmp_test = test[test!=0]\n",
    "train[\"weight_count\"] = (tmp_train*weight).sum(axis=1)\n",
    "test[\"weight_count\"] = (tmp_test*weight).sum(axis=1)\n",
    "train[\"count_not0\"] = (train != 0).sum(axis=1)\n",
    "test[\"count_not0\"] = (test != 0).sum(axis=1)\n",
    "train[\"sum\"] = train.sum(axis=1)\n",
    "test[\"sum\"] = test.sum(axis=1)\n",
    "train[\"var\"] = tmp_train.var(axis=1)\n",
    "test[\"var\"] = tmp_test.var(axis=1)\n",
    "train[\"median\"] = tmp_train.median(axis=1)\n",
    "test[\"median\"] = tmp_test.median(axis=1)\n",
    "train[\"mean\"] = tmp_train.mean(axis=1)\n",
    "test[\"mean\"] = tmp_test.mean(axis=1)\n",
    "train[\"std\"] = tmp_train.std(axis=1)\n",
    "test[\"std\"] = tmp_test.std(axis=1)\n",
    "train[\"max\"] = tmp_train.max(axis=1)\n",
    "test[\"max\"] = tmp_test.max(axis=1)\n",
    "train[\"min\"] = tmp_train.min(axis=1)\n",
    "test[\"min\"] = tmp_test.min(axis=1)\n",
    "train[\"skew\"] = tmp_train.skew(axis=1)\n",
    "test[\"skew\"] = tmp_test.skew(axis=1)\n",
    "train[\"kurtosis\"] = tmp_train.kurtosis(axis=1)\n",
    "test[\"kurtosis\"] = tmp_test.kurtosis(axis=1)\n",
    "del(tmp_train)\n",
    "del(tmp_test)\n",
    "NUM_OF_COM = 100 #need tuned\n",
    "transformer = random_projection.SparseRandomProjection(n_components = NUM_OF_COM)\n",
    "RP = transformer.fit_transform(tmp)\n",
    "rp = pd.DataFrame(RP)\n",
    "columns = [\"RandomProjection{}\".format(i) for i in range(NUM_OF_COM)]\n",
    "rp.columns = columns\n",
    "\n",
    "rp_train = rp[:ntrain]\n",
    "rp_test = rp[ntrain:]\n",
    "rp_test.index = test.index\n",
    "\n",
    "#concat RandomProjection and raw data\n",
    "train = pd.concat([train,rp_train],axis=1)\n",
    "test = pd.concat([test,rp_test],axis=1)\n",
    "\n",
    "del(rp_train)\n",
    "del(rp_test)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 1.3640 (0.0451)\n",
      "\n",
      "LGBM score: 1.3458 (0.0436)\n",
      "\n",
      "averaged score: 1.3461 (0.0448)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "#define evaluation method for a given model. we use k-fold cross validation on the training set. \n",
    "#the loss function is root mean square logarithm error between target and prediction\n",
    "#note: train and y_train are feeded as global variables\n",
    "NUM_FOLDS = 8 #need tuned\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(NUM_FOLDS, shuffle=True, random_state=random_seed).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "#ensemble method: model averaging\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    # the reason of clone is avoiding affect the original base models\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]  \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([ model.predict(X) for model in self.models_ ])\n",
    "        return np.mean(predictions, axis=1)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.055, colsample_bylevel =0.5, \n",
    "                             gamma=1.5, learning_rate=0.02, max_depth=32, \n",
    "                             objective='reg:linear',booster='gbtree',\n",
    "                             min_child_weight=57, n_estimators=1000, reg_alpha=0, \n",
    "                             reg_lambda = 0,eval_metric = 'rmse', subsample=0.7, \n",
    "                             silent=1, n_jobs = -1, early_stopping_rounds = 14,\n",
    "                             random_state =random_seed, nthread = -1)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=144,\n",
    "                              learning_rate=0.005, n_estimators=720, max_depth=13,\n",
    "                              metric='rmse',is_training_metric=True,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,verbose=-1,\n",
    "                              bagging_freq = 5, feature_fraction = 0.9) \n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n",
    "averaged_models = AveragingModels(models = (model_xgb, model_lgb))\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\"averaged score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_models.fit(train.values, y_train)\n",
    "pred = np.expm1(averaged_models.predict(test.values))\n",
    "ensemble = pred\n",
    "sub = pd.DataFrame()\n",
    "sub['ID'] = test_ID\n",
    "sub['target'] = ensemble\n",
    "sub.to_csv('../output/submission-ensemble.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
